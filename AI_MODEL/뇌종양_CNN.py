# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qVU9IkbRlrwxNAC9Pvbn6i-A7hoyAYLz
"""

from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
esc = EarlyStopping(monitor='val_loss',patience=20)
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras import *

#keras 라이브러리인 ImageDataGenerator를 불러옴

train_datagen = ImageDataGenerator(
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    rescale=1./255
)
#ImageDataGenerator 생성
#zoom_range = 이미지를 임의로 확대하거나 축소하는 범위
#width = 이미지의 폭을 임의로 이동시킬 범위
#height = 이미지의 높이를 임의로 이동할 범위
#shear = 이미지에 무작위 전단 변환을 적용하기 위한 범위

train_generator = train_datagen.flow_from_directory(
    "/content/drive/MyDrive/대청캠/데이터파일/조별과제 데이터/뇌종양 데이터/Data",
    target_size=(224, 224),
    batch_size=64,
    shuffle=True,
    class_mode='categorical'
)
#target_size = 데이터의 루트 디렉터리 경로
#batch_size = 훈련을 위한 배치 크기를 결정
#shuffle = 데이터를 무작위로 섞음 (True, False가 존재)
#class_mode = 다중 분류, 이중 분류로 나뉘며 각각, categorical, binary가 있음
def create_cnn_model(input_shape, num_classes):
    model = models.Sequential()

    # Convolutional Layer 1
    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Convolutional Layer 2
    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Convolutional Layer 3
    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))

    # Flatten Layer
    model.add(layers.Flatten())

    # Fully Connected Layer
    model.add(layers.Dense(64, activation='relu'))

    # Output Layer
    model.add(layers.Dense(num_classes, activation='softmax'))

    # Compile the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    return model

# CNN 모델 생성
input_shape = (224, 224, 3)  # 입력 이미지의 크기 (height, width, channels)
num_classes = train_generator.num_classes  # 레이블의 개수

cnn_model = create_cnn_model(input_shape, num_classes)

# 모델 학습

history = cnn_model.fit(train_generator, epochs=100, callbacks=[esc])

from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
esc = EarlyStopping(monitor='val_loss',patience=20)
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras import *

train_datagen = ImageDataGenerator(
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    "/content/drive/MyDrive/대청캠/데이터파일/조별과제 데이터/뇌종양 데이터/Data",
    target_size=(224, 224),
    batch_size=64,
    shuffle=True,
    class_mode='categorical')
def create_cnn_norm_model(input_shape, num_classes):
    model = models.Sequential()

    # Convolutional Layer 1
    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    # Convolutional Layer 2
    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    # Convolutional Layer 3
    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(layers.Conv2D(512, kernel_size=(3, 3), activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    # Flatten Layer
    model.add(layers.Flatten())

    # Fully Connected Layer
    model.add(layers.Dense(64, activation='relu'))

    model.add(Dropout(0.5))


    # Output Layer
    model.add(layers.Dense(num_classes, activation='softmax'))

    # Compile the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    return model

input_shape = (224, 224, 3)  # 입력 이미지의 크기 (height, width, channels)
num_classes = train_generator.num_classes  # 레이블의 개수

cnn_norm_model = create_cnn_norm_model(input_shape, num_classes)

# 모델 학습

history = cnn_norm_model.fit(train_generator, epochs=100, callbacks=[esc])

import matplotlib.pyplot as plt
y_loss = history.history['loss']
plt.plot(history.history['loss'])
plt.title('loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['loss'], loc = 'lower right')
plt.show()

